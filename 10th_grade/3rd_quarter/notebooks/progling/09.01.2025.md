## Задание

### **Тема: Мешок слов и Word2Vec**

#### **Дедлайн**: 12.01.25 23:59

### Задание
#### Пункт 1: подготовка данных
1. Возьмите несколько рассказов / отрывков текста (от 10 штук), желательно, из одной серии или схожей тематики. 
2. Подготовьте тексты для обучения модели:
    - лемматизируйте тексты
    - приведите к нижнему регистру
    - уберите знаки препинания
    - исключите стоп-слова (предлоги, местоимения и прочее)
    - запишите все тексты в один файл, каждое предложение на отдельной строке

#### Пункт 2: BoW
1. Составьте словарь частотности слов и ограничьте его первыми 100 самыми частотными словами (если их меньше 100, увеличьте отрывки текстов).
2. Создайте вектора каждого текста, где 1 будет означать наличие слова из словаря в тексте, а 0 — отсутствие. У вас получится по двоичному массиву для каждого текста.

#### Пункт 3: Word2Vec
1. Обучите модель как показано в конспекте по word2vec с параметрами
      - размер вектора 300
      - минимальное количество вхождений 5
      - окно 5
      - количество итераций 50
2. Сколько слов оказалось в словаре? Это много или мало? 
3. Найдите ближайшие 10 слов для:
      - абстрактного понятия
      - любых двух антонимов (хороший/плохой, холодный/горячий, etc)
4. Кратко опишите результаты предыдущего пункта: 
      - насколько ожидаем такой результат? есть ли неожиданные соседи?
      - есть ли синонимы / антонимы в ближайших к слову?
      - говорит ли это что-то о самом корпусе? (есть ли какие-то особенности относительно языка в целом)

**Что сдать**
1. Тетрадка с кодом в формате IPYNB
2. Файл с текстами из п. 1 в формате TXT.

#### Критерии оценки
Является обязательным оформление домашней работы в Jupyter Notebook с ответами на вопросы, комментариями и по PEP-8.
<table>
    <tr><th>Макс. балл</th><th>Критерий</th></tr>
    <tr><td>3</td><td>пункт 1</td></tr>    
    <tr><td>3</td><td>пункт 2</td></tr> 
    <tr><td>4</td><td>пункт 3</td></tr> 
</table>
